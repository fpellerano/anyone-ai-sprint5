{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1921907412.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [1]\u001b[1;36m\u001b[0m\n\u001b[1;33m    Model Evaluation Report\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Model Evaluation Report\n",
    "\n",
    "Experimentation:\n",
    "\n",
    "Classification of vehicle images using the convolutional neural network called [ResNet50](https://www.kaggle.com/datasets/keras/resnet50)\n",
    "\n",
    "- Transfer Learning \n",
    "- Fine-Tuning \n",
    "\n",
    "Hardware specifications of server used for training:\n",
    "    AWS Elastic Computing (EC2) cloud server\n",
    "    GPU:\n",
    "    NVIDIA-SMI 470.129.06   \n",
    "    Driver Version: 470.129.06   \n",
    "    CUDA Version: 11.4 \n",
    "    Model: Tesla K80 \n",
    "    Memory: 11.441 MiB \n",
    "\n",
    "Dataset\n",
    "    Exploratory Data Analysis:\n",
    "    Model tranining was based on a vehicle dataset of 16,185 images divided in 196 different classes.\n",
    "    I split to train 8144 and to test 8041 images. \n",
    "\n",
    "    Dataset processing:\n",
    "    Later on the project a background removal was applied image by image with an object detection algoritm called Faster R-CNN (specially faster_rcnn_R_101_FPN_3x) from [Detectron2](https://ai.facebook.com/tools/detectron2/) platform to identify vehicles area and crop the image in order to have a more accurate input.\n",
    "\n",
    "    Dataset: \n",
    "        Images of vehicles: 16,185 \n",
    "        classes: 196\t\n",
    "        D. Train: 8144\n",
    "        D. Validation: 20% to 8144\n",
    "        D. Test: 8041\n",
    "        Models: \n",
    "            Resnet50\n",
    "            Weights: imagenet\n",
    "            Image_size: [224, 224],\n",
    "            Batch_size: 32\n",
    "            Dropout_rate: 0.2\n",
    "            Data_aug_layer: \n",
    "                random_flip: {'mode': 'horizontal_and_vertical'},\n",
    "                random_rotation: {'factor': 0.2},\n",
    "                random_zoom: {'height_factor': 0.2, 'width_factor': 0.2}\n",
    "            Optimizer: 'Adam'\n",
    "            Loss: 'categorical_crossentropy',\n",
    "            Metrics: 'accuracy'\n",
    "            fit: \n",
    "                epochs: 150\n",
    "    =================================================================\n",
    "\n",
    "    Experiment 001: Transfer Learning and 25 epochs, see more: experiment/exp_001/config.yml\n",
    "    \n",
    "    Model: \"model\"\n",
    "    _________________________________________________________________\n",
    "    Layer (type)                Output Shape              Param #   \n",
    "    =================================================================\n",
    "    Input (InputLayer)          [(None, 224, 224, 3)]     0         \n",
    "                                                                    \n",
    "    sequential (Sequential)     (None, 224, 224, 3)       0         \n",
    "                                                                    \n",
    "    tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
    "    licingOpLambda)                                                 \n",
    "                                                                    \n",
    "    tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
    "                                                                    \n",
    "    resnet50 (Functional)       (None, 2048)              23587712  \n",
    "                                                                    \n",
    "    dropout (Dropout)           (None, 2048)              0         \n",
    "                                                                    \n",
    "    dense (Dense)               (None, 196)               401604    \n",
    "                                                                    \n",
    "    =================================================================\n",
    "    Total params: 23,989,316\n",
    "    Trainable params: 401,604\n",
    "    Non-trainable params: 23,587,712\n",
    "    \n",
    "    Result: \n",
    "    Your model accuracy is 15,52%\n",
    "\n",
    "    =================================================================\n",
    "\n",
    "    Experiment 002: Transfer Learning, remove background and 150 epochs, see more: experiment/exp_002/config.yml  \n",
    "    Model: \"model\"\n",
    "    _________________________________________________________________\n",
    "    Layer (type)                Output Shape              Param #   \n",
    "    =================================================================\n",
    "    Input (InputLayer)          [(None, 224, 224, 3)]     0         \n",
    "                                                                    \n",
    "    sequential (Sequential)     (None, 224, 224, 3)       0         \n",
    "                                                                    \n",
    "    tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
    "    licingOpLambda)                                                 \n",
    "                                                                    \n",
    "    tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
    "                                                                    \n",
    "    resnet50 (Functional)       (None, 2048)              23587712  \n",
    "                                                                    \n",
    "    dropout (Dropout)           (None, 2048)              0         \n",
    "                                                                    \n",
    "    dense (Dense)               (None, 196)               401604    \n",
    "                                                                    \n",
    "    =================================================================\n",
    "    Total params: 23,989,316\n",
    "    Trainable params: 401,604\n",
    "    Non-trainable params: 23,587,712\n",
    "\n",
    "    Result:   \n",
    "    Your model accuracy is 41,09%\n",
    "\n",
    "    =================================================================\n",
    "    \n",
    "    Experiment 003: Fine tuning, remove background and 150 epochs, see more: experiment/exp_002/config.yml  \n",
    "    Model: \"model\"\n",
    "    _________________________________________________________________\n",
    "    Layer (type)                Output Shape              Param #   \n",
    "    =================================================================\n",
    "    Input (InputLayer)          [(None, 224, 224, 3)]     0         \n",
    "                                                                    \n",
    "    sequential (Sequential)     (None, 224, 224, 3)       0         \n",
    "                                                                    \n",
    "    tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
    "    licingOpLambda)                                                 \n",
    "                                                                    \n",
    "    tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
    "                                                                    \n",
    "    resnet50 (Functional)       (None, 2048)              23587712  \n",
    "                                                                    \n",
    "    dropout (Dropout)           (None, 2048)              0         \n",
    "                                                                    \n",
    "    dense (Dense)               (None, 196)               401604    \n",
    "                                                                    \n",
    "    =================================================================\n",
    "    Total params: 23,989,316\n",
    "    Trainable params: 23,936,196\n",
    "    Non-trainable params: 53,120\n",
    "\n",
    "    Result:   \n",
    "    Your model accuracy is 70,64 %\n",
    "\n",
    "    =================================================================\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "During the evaluation of all experiments I can conclude that the following data: \n",
    "\n",
    "- Turning from Transfer learning to Fine-Tuning training unfreezeing all of the base model and retrain the whole model end-to-end.\n",
    "- Decreasing learning rate and increase training epochs.\n",
    "- Decreasing data augmentation rate.\n",
    "- Replacing translation data augmentation layer by contrast data augmentation.\n",
    "- L2 kernel regularization on dense layer performs better than Elastic Net (l1_l2).\n",
    "- Cropping images background improves train and validation accuracy significantly.\n",
    "\n",
    "## What can be improved\n",
    "Dataset\n",
    "- Obtain more images to dataset.\n",
    "- Optimize training data with \"K-Fold Cross-Validation\" to divide the images into K parts of equal size and then train the model K number of times with a different training and validation set.\n",
    "\n",
    "Model \n",
    "- Try with different data augmentation layer (e.g adding Random Brightness)\n",
    "- Increase kernel regularization rate on dense model layer.\n",
    "- Try adding kernel regularization on more layers.\n",
    "- Do ensemble learning combining the predictions from multiple models.\n",
    "\n",
    "Model compilation\n",
    "- Tune epsilon hyperparameter in Adam Optimizer.\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4915acf6e5034796ebe246aec42ef0455937f82fed9a8402bd19f589d5a43f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
